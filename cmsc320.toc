\babel@toc {english}{}
\contentsline {section}{\numberline {1}Notes \& Preface}{6}{section.1}
\contentsline {section}{\numberline {2}Introduction (L1)}{6}{section.2}
\contentsline {subsection}{What is Data Science?}{6}{section.2}
\contentsline {subsection}{Topics}{6}{section.2}
\contentsline {subsection}{Tools}{6}{section.2}
\contentsline {subsection}{Conda}{7}{section.2}
\contentsline {section}{\numberline {3}Python, Jupyter, Literate Programming (L2)}{7}{section.3}
\contentsline {subsection}{Literate Programming}{7}{section.3}
\contentsline {subsection}{Jupyter Notebook + Alternatives}{7}{section.3}
\contentsline {subsection}{List Comprehensions in Python}{7}{section.3}
\contentsline {subsection}{Using Python3}{8}{section.3}
\contentsline {subsection}{Python vs. R for Data Scientists}{8}{section.3}
\contentsline {subsection}{The Classic Statistical View of Data}{9}{section.3}
\contentsline {subsubsection}{Nominal Data}{9}{section.3}
\contentsline {subsubsection}{Ordinal Data}{9}{section.3}
\contentsline {subsubsection}{Interval and Ratio Data}{10}{section.3}
\contentsline {subsection}{Data Science at a Glance}{10}{section.3}
\contentsline {section}{\numberline {4}Getting Data to Work With (L3)}{11}{section.4}
\contentsline {subsection}{Acquiring Data}{11}{section.4}
\contentsline {subsection}{RESTful APIs}{12}{section.4}
\contentsline {subsection}{Oauth}{12}{section.4}
\contentsline {subsection}{GET Requests}{12}{section.4}
\contentsline {subsection}{More on Data Storage Formats}{13}{section.4}
\contentsline {subsubsection}{SAX}{13}{section.4}
\contentsline {subsection}{Parsing HTML}{13}{section.4}
\contentsline {section}{\numberline {5}NumPy, Best Practices, Ethics (L4)}{13}{section.5}
\contentsline {subsection}{Available Technologies}{13}{section.5}
\contentsline {subsection}{NumPy Stack}{14}{section.5}
\contentsline {subsubsection}{Misc About NumPy}{14}{section.5}
\contentsline {subsubsection}{Linear Algebra with NumPy}{14}{section.5}
\contentsline {subsubsection}{SciPy}{15}{lstnumber.-1.4}
\contentsline {subsection}{The Idea of Reproducibility}{15}{lstnumber.-1.4}
\contentsline {subsection}{Best Practices}{15}{lstnumber.-1.4}
\contentsline {subsection}{The Idea of Open Data}{15}{lstnumber.-1.4}
\contentsline {subsection}{General Process}{15}{lstnumber.-1.4}
\contentsline {subsection}{Project Organization}{16}{lstnumber.-1.4}
\contentsline {subsection}{A Little on Bias, Ethics, Responsibility}{16}{lstnumber.-1.4}
\contentsline {section}{\numberline {6}Tables, Relational DB, and Pandas (L5 + L6)}{17}{section.6}
\contentsline {subsection}{Tables}{17}{section.6}
\contentsline {subsubsection}{Selecting / Slicing}{17}{section.6}
\contentsline {subsubsection}{Aggregating / Reducing}{17}{section.6}
\contentsline {subsubsection}{Map}{18}{section.6}
\contentsline {subsubsection}{Group By}{18}{section.6}
\contentsline {subsubsection}{Group By + Aggregate}{19}{section.6}
\contentsline {subsubsection}{Union, Intersection, Difference}{19}{section.6}
\contentsline {subsubsection}{Merge or Join}{19}{section.6}
\contentsline {subsubsection}{Summary}{19}{section.6}
\contentsline {subsection}{Pandas}{20}{section.6}
\contentsline {subsubsection}{Dataframes}{20}{section.6}
\contentsline {subsubsection}{Series}{20}{section.6}
\contentsline {subsubsection}{Creating a Dataframe}{21}{section.6}
\contentsline {subsection}{Tidy Data}{21}{section.6}
\contentsline {subsection}{SQL and Relational Databases}{22}{section.6}
\contentsline {subsubsection}{Indexing}{22}{section.6}
\contentsline {subsection}{Relationships}{23}{section.6}
\contentsline {subsection}{SQL and SQLite}{24}{section.6}
\contentsline {subsection}{Joining Data}{25}{section.6}
\contentsline {subsubsection}{Types of Joins}{25}{section.6}
\contentsline {subsubsection}{Syntax in PANDAS}{27}{section.6}
\contentsline {subsubsection}{Visual Example}{28}{lstnumber.-3.15}
\contentsline {section}{\numberline {7}Version Control Software (L7)}{28}{section.7}
\contentsline {subsection}{Centralized VCS}{28}{section.7}
\contentsline {subsection}{Distributed VCS}{29}{section.7}
\contentsline {subsection}{Branching}{29}{section.7}
\contentsline {subsubsection}{When Should I Branch?}{29}{section.7}
\contentsline {subsection}{Git Basics}{29}{section.7}
\contentsline {subsection}{Online Hosting}{30}{section.7}
\contentsline {section}{\numberline {8}Missing Data and Imputation (L8)}{30}{section.8}
\contentsline {subsection}{Missing Data}{30}{section.8}
\contentsline {subsubsection}{Just Deleting It}{31}{section.8}
\contentsline {subsection}{Types of Missing Data}{31}{section.8}
\contentsline {subsubsection}{Missing Completely At Random}{31}{section.8}
\contentsline {subsubsection}{Missing At Random}{31}{section.8}
\contentsline {subsubsection}{Missing Not At Random}{32}{section.8}
\contentsline {subsection}{Line of Best Fit}{32}{section.8}
\contentsline {subsection}{Imputation}{33}{section.8}
\contentsline {subsubsection}{Types Of Imputation}{33}{section.8}
\contentsline {subsubsection}{Single vs. Multiple Imputation}{33}{section.8}
\contentsline {section}{\numberline {9}Data Wrangling, Integration, Cleaning (L9)}{33}{section.9}
\contentsline {subsection}{Data Wrangling}{34}{section.9}
\contentsline {subsubsection}{Key Steps of Data Wrangling}{34}{section.9}
\contentsline {subsection}{Data Integration}{34}{section.9}
\contentsline {subsection}{Data Cleaning}{35}{section.9}
\contentsline {subsubsection}{Types of Data Quality Issues}{36}{section.9}
\contentsline {subsubsection}{Outlier Detection}{36}{section.9}
\contentsline {subsubsection}{Entity Resolution}{36}{section.9}
\contentsline {section}{\numberline {10}Statistics Review (L10)}{37}{section.10}
\contentsline {subsection}{Exploratory Data Analysis}{37}{section.10}
\contentsline {subsection}{Summary Statistics - Overview}{37}{section.10}
\contentsline {subsection}{Measures of Location}{37}{section.10}
\contentsline {subsection}{Measures of Dispersion}{38}{section.10}
\contentsline {subsection}{Correlation}{39}{section.10}
\contentsline {subsection}{Standardization}{39}{section.10}
\contentsline {section}{\numberline {11}Networks and Graphs (L11)}{40}{section.11}
\contentsline {subsection}{Review on Graphs}{40}{section.11}
\contentsline {subsection}{NetworkX}{42}{section.11}
\contentsline {subsection}{Graph Databases}{42}{section.11}
\contentsline {subsection}{Centrality Analysis}{42}{section.11}
\contentsline {subsection}{Network Topology}{43}{section.11}
\contentsline {section}{\numberline {12}Natural Language Processing (L14 + 15)}{43}{section.12}
\contentsline {subsection}{Background}{44}{section.12}
\contentsline {subsection}{Natural Language Processing Terminology}{45}{section.12}
\contentsline {subsection}{Spoken Dialogue System (Example)}{46}{section.12}
\contentsline {subsection}{General Industry}{46}{section.12}
\contentsline {subsection}{Supervised Learning}{47}{section.12}
\contentsline {subsection}{NLP In Python}{48}{section.12}
\contentsline {subsection}{Distributional Models of Meaning}{49}{section.12}
\contentsline {subsection}{Document Matrices}{49}{section.12}
\contentsline {subsection}{Measuring Similarity}{49}{section.12}
\contentsline {subsubsection}{Using The Dot Product}{49}{section.12}
\contentsline {subsubsection}{Normalizing Dot Product: Cosine Similarity}{50}{section.12}
\contentsline {subsubsection}{Example: Calculating Cosine Similarity}{50}{section.12}
\contentsline {subsubsection}{Minimum Edit Distance}{51}{section.12}
\contentsline {subsection}{Representing Text with N-Grams}{52}{section.12}
\contentsline {subsubsection}{Probabilities}{52}{section.12}
\contentsline {section}{\numberline {13}Machine Learning (L16 + 19)}{52}{section.13}
\contentsline {subsection}{Overview}{52}{section.13}
\contentsline {subsection}{Hypothesis}{53}{section.13}
\contentsline {subsubsection}{Hypothesis Function}{53}{section.13}
\contentsline {subsubsection}{Hypothesis Space}{54}{section.13}
\contentsline {subsection}{The Loss Function}{54}{section.13}
\contentsline {subsection}{The Canonical Machine Learning Problem}{54}{section.13}
\contentsline {subsection}{Overarching Idea}{55}{section.13}
\contentsline {subsection}{Examples of ML Algorithms}{55}{section.13}
\contentsline {subsection}{Example: Linear Regression As Machine Learning}{55}{section.13}
\contentsline {subsection}{Machine Learning in Python}{57}{section.13}
\contentsline {subsection}{(Stochastic) Gradient Descent}{57}{section.13}
\contentsline {subsubsection}{Procedure}{58}{section.13}
\contentsline {subsubsection}{Batch vs. Stochastic Gradient Descent}{59}{section.13}
\contentsline {section}{\numberline {14}Decision Trees (L20)}{59}{section.14}
\contentsline {subsection}{Big Picture of Learning}{59}{section.14}
\contentsline {subsection}{Decision Trees Intro}{59}{section.14}
\contentsline {subsubsection}{Example: Election Decision Tree}{60}{section.14}
\contentsline {subsection}{Decision Tree Learning Algorithm (ID3)}{61}{section.14}
\contentsline {subsubsection}{Badminton Example: Hackerearth}{62}{section.14}
\contentsline {subsubsection}{ID3 Algorithm}{63}{section.14}
\contentsline {subsubsection}{Information Gain + Entropy}{63}{section.14}
\contentsline {subsubsection}{Example: Information Gain + Entropy}{65}{section.14}
\contentsline {subsection}{Noisy Data}{66}{section.14}
\contentsline {subsection}{Overfitting}{66}{section.14}
\contentsline {subsubsection}{Example: Overfitting}{66}{section.14}
\contentsline {subsubsection}{Defining Overfitting}{67}{section.14}
\contentsline {subsection}{Evaluation Methodology}{68}{section.14}
\contentsline {subsubsection}{Standard Methodology: Holdout Cross-Validation}{68}{section.14}
\contentsline {subsection}{Learning Curve Graph}{68}{section.14}
\contentsline {subsection}{Precision vs. Recall}{68}{section.14}
\contentsline {subsection}{Decision Trees in Scikit}{68}{section.14}
\contentsline {subsection}{Random Forests}{69}{lstnumber.-4.10}
\contentsline {subsubsection}{Bagging}{69}{lstnumber.-4.10}
\contentsline {section}{\numberline {15}K-Nearest Neighbors \& Support Vector Machines (L21)}{70}{section.15}
\contentsline {subsection}{Overview}{70}{section.15}
\contentsline {subsection}{Using Nearest Neighbors}{72}{section.15}
\contentsline {subsection}{Choosing a Value for $k$}{72}{section.15}
\contentsline {subsection}{Scaling}{72}{section.15}
\contentsline {subsection}{Curse of Dimensionality}{73}{section.15}
\contentsline {subsubsection}{K-NN is Lazy}{73}{section.15}
\contentsline {subsection}{Nearest Neighbor Search}{74}{section.15}
\contentsline {subsubsection}{Exact Methods}{75}{section.15}
\contentsline {subsubsection}{Approximation Methods}{78}{section.15}
\contentsline {subsection}{Advantages of K-NN}{79}{section.15}
\contentsline {subsection}{Disadvantages of K-NN}{79}{section.15}
\contentsline {subsection}{K-NN Classification in Scikit-Learn}{79}{section.15}
\contentsline {subsection}{K-NN Regression}{79}{lstnumber.-5.9}
\contentsline {subsection}{Support Vector Machines}{80}{lstnumber.-5.9}
\contentsline {subsubsection}{If the Decision Boundary Is Not Linear}{82}{lstnumber.-5.9}
\contentsline {subsubsection}{SVMs in Scikit-Learn}{83}{lstnumber.-5.9}
\contentsline {section}{\numberline {16}Nonlinear Regression \& Regularization (L22 + 23)}{83}{section.16}
\contentsline {subsection}{Generalization Error}{83}{section.16}
\contentsline {subsubsection}{Training vs. Generalization Loss}{84}{section.16}
\contentsline {subsubsection}{Cross-Validation}{84}{section.16}
\contentsline {subsection}{Regularization}{84}{section.16}
\contentsline {subsection}{Unsupervised Learning}{85}{section.16}
\contentsline {subsection}{K-Means Clustering}{86}{section.16}
\contentsline {subsubsection}{How K-Means fits Into the Unsupervised Framework Paradigm}{86}{section.16}
\contentsline {subsubsection}{K-Means Clustering Algorithm}{87}{section.16}
\contentsline {subsubsection}{How Do We Select $k$?}{87}{section.16}
\contentsline {subsubsection}{Example of K-Means Clustering}{87}{section.16}
\contentsline {subsection}{Principal Component Analysis}{88}{section.16}
\contentsline {subsubsection}{3-Dimensional Example}{88}{section.16}
\contentsline {subsubsection}{17-Dimensional Example}{91}{section.16}
\contentsline {subsection}{General Notes}{92}{section.16}
\contentsline {subsection}{Recommender Systems}{93}{section.16}
\contentsline {subsection}{Collaborative Filtering}{93}{section.16}
\contentsline {subsubsection}{Overview}{93}{section.16}
\contentsline {subsubsection}{Approaches}{94}{section.16}
\contentsline {subsection}{Association Rules}{95}{section.16}
\contentsline {subsubsection}{Examples}{95}{section.16}
\contentsline {subsubsection}{Basic Concepts of Association Rules}{95}{section.16}
\contentsline {subsubsection}{Miscellaneous}{96}{table.caption.1}
\contentsline {subsubsection}{In Practice}{96}{table.caption.1}
\contentsline {section}{\numberline {17}Big Data and MapReduce (L24)}{96}{section.17}
\contentsline {subsection}{Big Data}{96}{section.17}
\contentsline {subsection}{MapReduce}{97}{section.17}
\contentsline {subsubsection}{Overview}{97}{section.17}
\contentsline {subsubsection}{Hadoop}{97}{section.17}
\contentsline {subsubsection}{MapReduce Details}{97}{section.17}
\contentsline {subsubsection}{How MapReduce Works}{98}{section.17}
\contentsline {subsubsection}{Key Notes about Mappers/Reducers}{98}{section.17}
\contentsline {subsubsection}{MapReduce's Pros and Cons}{99}{section.17}
\contentsline {subsubsection}{MapReduce in Python}{99}{section.17}
\contentsline {section}{\numberline {18}Probability Review (L25)}{99}{section.18}
\contentsline {subsection}{Review of Probability}{99}{section.18}
\contentsline {subsubsection}{Basics}{99}{section.18}
\contentsline {subsubsection}{Bayes Theorem}{100}{section.18}
\contentsline {subsection}{Hypothesis Testing}{100}{section.18}
\contentsline {subsubsection}{Background Information}{101}{section.18}
\contentsline {subsubsection}{Rejecting vs. Not Rejecting the Null}{102}{section.18}
\contentsline {subsubsection}{What's the Point?}{102}{section.18}
\contentsline {subsubsection}{General Steps}{102}{section.18}
\contentsline {subsection}{Sample Statistics}{102}{section.18}
\contentsline {section}{\numberline {19}Footnotes}{103}{section.19}
